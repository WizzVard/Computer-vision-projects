{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee817c2-52e4-460a-86d9-05f0c2fad83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage.filters import threshold_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b8a874-070c-4bfb-8d05-46d51323716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest_contour(contours):\n",
    "    biggest = np.array([])\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i)\n",
    "        if area > 1000:\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.015 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "    return biggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc597de0-b487-487b-b023-63dfa95967fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_cnts(contours):\n",
    "    questionCnts = []\n",
    "    if len(contours) > 0:\n",
    "        for c in cnts: \n",
    "            # compute the bounding box of the contour, then use the bounding box to derive the aspect ratio\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            ar = w / float(h)\n",
    "            # in order to label the contour as a question, region should be sufficiently wide, sufficiently tall,\n",
    "            # and have an aspect ratio approximately equal to 1\n",
    "            if w >= 10 and h >= 10 and ar >= 0.8  and ar <= 1.2:\n",
    "                questionCnts.append(c)\n",
    "\n",
    "    return questionCnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fb708c-9cbf-4f76-b1a2-abc595052609",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Resources/bubble_sheet.png')\n",
    "(h, w, d) = image.shape\n",
    "ratio = 300.0 / w\n",
    "dim = (300, int(h*ratio))\n",
    "img = cv2.resize(image, dim)\n",
    "img_original = img.copy()\n",
    "\n",
    "gray = cv2.cvtColor(img_original, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.bilateralFilter(gray, 20, 30, 30)\n",
    "edged = cv2.Canny(blurred, 75, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef9d6c-3a91-4f87-9d2c-288a9c64970a",
   "metadata": {},
   "source": [
    "## Find contours of paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa00b92-637d-4e1a-bb4c-d8c5250e8577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 50,  74,  85],\n",
       "        [ 52,  78,  89],\n",
       "        [ 54,  80,  91],\n",
       "        ...,\n",
       "        [ 66,  91, 101],\n",
       "        [ 62,  88,  98],\n",
       "        [ 61,  87,  98]],\n",
       "\n",
       "       [[ 52,  78,  89],\n",
       "        [ 49,  74,  85],\n",
       "        [ 51,  77,  88],\n",
       "        ...,\n",
       "        [ 70,  94, 104],\n",
       "        [ 59,  85,  96],\n",
       "        [ 70,  94, 104]],\n",
       "\n",
       "       [[ 48,  72,  83],\n",
       "        [ 50,  75,  86],\n",
       "        [ 52,  78,  89],\n",
       "        ...,\n",
       "        [ 59,  85,  96],\n",
       "        [ 68,  93, 103],\n",
       "        [ 60,  86,  97]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 49,  74,  85],\n",
       "        [ 41,  63,  73],\n",
       "        [ 41,  63,  74],\n",
       "        ...,\n",
       "        [ 58,  84,  95],\n",
       "        [ 67,  91, 102],\n",
       "        [ 58,  84,  95]],\n",
       "\n",
       "       [[ 46,  70,  81],\n",
       "        [ 50,  75,  86],\n",
       "        [ 45,  69,  79],\n",
       "        ...,\n",
       "        [ 54,  80,  91],\n",
       "        [ 57,  83,  94],\n",
       "        [ 58,  84,  95]],\n",
       "\n",
       "       [[ 47,  70,  81],\n",
       "        [ 45,  68,  79],\n",
       "        [ 49,  74,  85],\n",
       "        ...,\n",
       "        [ 60,  86,  97],\n",
       "        [ 53,  79,  90],\n",
       "        [ 65,  90, 101]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RETR_EXTERNAL retrieves only the extreme outer contours\n",
    "# cv2.CHAIN_APPROX_SIMPLE: This is the contour approximation method\n",
    "cnts, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# select 10 biggest contours\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "# Now lets search for the biggest contour that has 4 corners\n",
    "biggest = biggest_contour(cnts)\n",
    "\n",
    "cv2.drawContours(img, [biggest], -1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7322b0af-91df-4aa6-ab7f-519f510cd166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 525, 3)\n",
      "(400, 300, 3)\n",
      "(400, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "# Image shape modification for hstack\n",
    "blurred = np.stack((blurred,) * 3, axis=-1)\n",
    "edged = np.stack((edged,) * 3, axis=-1)\n",
    "\n",
    "print(image.shape)\n",
    "print(blurred.shape)\n",
    "print(edged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41980ab-b6e9-497b-8f68-6f6ca56107f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_hor = np.hstack((img_original, blurred, edged, img))\n",
    "cv2.imshow(\"Contour detection\", img_hor)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b326b-bec3-42a9-8f6c-431825ba6f1c",
   "metadata": {},
   "source": [
    "# Determine corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a2e847-0348-4ec5-82f2-d1d03f8c16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Reshape contour points to have 4 lists with 2 places in the list. \n",
    "# It represents our 4 corners with x and y cordinates.\n",
    "points = biggest.reshape(4, 2) \n",
    "# we create empty array where we will store coordinates in the correct order.\n",
    "input_points = np.zeros((4, 2), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3faf4f18-a90b-4cb2-817c-0af274e346be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to mantain the same corner points order as we used before:\n",
    "# top_left, top_right, bottom_left, bottom_right\n",
    "\n",
    "# top_left and bottom right coordinates we can get with sum of the x and y coodinates\n",
    "points_sum = points.sum(axis=1)\n",
    "# top left point will have the smallest sum\n",
    "input_points[0] = points[np.argmin(points_sum)]\n",
    "# bottom right will have the biggest sum\n",
    "input_points[3] = points[np.argmax(points_sum)]\n",
    "\n",
    "# top right and bottom left points we can get by taking the difference between x and y cords\n",
    "points_diff = np.diff(points, axis=1)\n",
    "# top right point will have the smallest difference\n",
    "input_points[1] = points[np.argmin(points_diff)]\n",
    "# bottom left will have the biggest difference\n",
    "input_points[2] = points[np.argmax(points_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11fcb9a2-3d69-4fa9-a124-95d0f17edeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to calculate the dimensions of our new image\n",
    "# We will calculate the distance between points coordinates\n",
    "(top_left, top_right, bottom_left, bottom_right) = input_points\n",
    "# calculate the bottom width of the image by computing the dist between x and y cords of the bot right and bot left points\n",
    "bottom_width = np.sqrt(((bottom_right[0] - bottom_left[0]) ** 2) + ((bottom_right[1] - bottom_left[1]) ** 2))\n",
    "# the same logic for next 3 widths\n",
    "top_width = np.sqrt(((top_right[0] - top_left[0]) ** 2) + ((top_right[1] - top_left[1]) ** 2))\n",
    "right_width = np.sqrt(((top_right[0] - bottom_right[0]) ** 2) + ((top_right[1] - bottom_right[1]) ** 2))\n",
    "left_width = np.sqrt(((top_left[0] - bottom_left[0]) ** 2) + ((top_left[1] - bottom_left[1]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f4a09d2-7c0e-4b04-98eb-bdc3622d54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output image size\n",
    "# As we don't know the exact dimention, we will use the maximum width and hight\n",
    "max_width = max(int(bottom_width), int(top_width))\n",
    "# max_height = max(int(right_height), int(left_height))\n",
    "max_hight = int(max_width * 1.414) # for A4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab360590-e6ba-42f9-839c-bda40f6b6a80",
   "metadata": {},
   "source": [
    "## Perspective transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32ccb5dc-4095-4bc4-b5f8-ff058f674659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired points values in the output image\n",
    "converted_points = np.float32([[0, 0], [max_width, 0], [0, max_hight], [max_width, max_hight]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba883f18-c201-4ce3-bc45-d5dc902cf8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective transformation\n",
    "matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "img_output = cv2.warpPerspective(img_original, matrix, (max_width, max_hight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d8dec-dae6-4fcf-969c-6064fbbf3f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dd7b111-2078-469c-b187-dffa1ec55a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img_output, cv2.COLOR_BGR2GRAY)\n",
    "# blurred = cv2.bilateralFilter(gray, 10, 10, 10)\n",
    "# edged = cv2.Canny(blurred, 100, 200)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "643259c3-6534-4431-a5be-9b6535dd24dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 186, 3)\n",
      "(263, 186, 3)\n"
     ]
    }
   ],
   "source": [
    "# Image shape modification for hstack\n",
    "stack_im = np.stack((thresh,) * 3, axis=-1)\n",
    "\n",
    "print(img_output.shape)\n",
    "print(stack_im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e90562-70da-4b0f-bf4c-d8d5685f68e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77dee99e-9c86-4820-83ce-8909ccf23f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the answer key which maps the question number to the correct answer\n",
    "ANSWER_KEY = {0: 1, 1: 4, 2: 0, 3: 3, 4: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89b0dc71-43bd-47b7-8225-230c76c2f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_copy = img_output.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9211fa0-a3db-48ef-b26f-fe2e33d5b2e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 89, 111, 119],\n",
       "        [ 93, 114, 122],\n",
       "        [ 93, 114, 122],\n",
       "        ...,\n",
       "        [235, 239, 238],\n",
       "        [238, 242, 240],\n",
       "        [234, 238, 239]],\n",
       "\n",
       "       [[193, 202, 203],\n",
       "        [192, 201, 203],\n",
       "        [195, 203, 205],\n",
       "        ...,\n",
       "        [234, 238, 236],\n",
       "        [238, 242, 240],\n",
       "        [228, 233, 234]],\n",
       "\n",
       "       [[202, 211, 212],\n",
       "        [196, 207, 209],\n",
       "        [200, 210, 212],\n",
       "        ...,\n",
       "        [233, 237, 235],\n",
       "        [236, 239, 238],\n",
       "        [220, 226, 227]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[156, 167, 169],\n",
       "        [165, 184, 192],\n",
       "        [164, 183, 191],\n",
       "        ...,\n",
       "        [251, 253, 253],\n",
       "        [251, 253, 253],\n",
       "        [251, 253, 253]],\n",
       "\n",
       "       [[165, 179, 183],\n",
       "        [163, 182, 189],\n",
       "        [163, 182, 189],\n",
       "        ...,\n",
       "        [251, 253, 253],\n",
       "        [251, 253, 253],\n",
       "        [251, 253, 253]],\n",
       "\n",
       "       [[165, 179, 184],\n",
       "        [164, 183, 191],\n",
       "        [164, 183, 191],\n",
       "        ...,\n",
       "        [245, 248, 248],\n",
       "        [245, 247, 247],\n",
       "        [248, 250, 250]]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "questionCnts = question_cnts(cnts)\n",
    "cv2.drawContours(warped_copy, questionCnts, -1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acd0e610-7db5-433a-8cb0-9235244e1f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_hor = np.hstack((img_output, stack_im, warped_copy))\n",
    "cv2.imshow(\"Answers detection\", img_hor)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf51e7f4-8b94-4795-88cf-ce913b64a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the question contours top-to-bottom, then initiaize the total number of correct answers\n",
    "questionCnts = sorted(questionCnts, key=lambda x: cv2.boundingRect(x)[1])\n",
    "correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd28d220-3ab4-4fbe-ab6a-5bdb3c363828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] score: 80.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each question has 5 possible answers, to loop over the question in batches of 5\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]\n",
    "\n",
    "# Initialize the index of the bubbled answer\n",
    "row_idx = 0\n",
    "\n",
    "# Initialize an empty list to store the sorted contours\n",
    "sorted_cnts = []\n",
    "\n",
    "# Iterate over the contours in groups of 5\n",
    "for (q, i) in enumerate(np.arange(0, len(questionCnts), 5)):\n",
    "    # Sort the contours for the current question from left to right\n",
    "    # If i is 0, the slice questionCnts[0:5] will contain the first 5 contours.\n",
    "    cnts = sorted(questionCnts[i : i+5], key=lambda x: cv2.boundingRect(x)[0])\n",
    "    sorted_cnts.extend(cnts)  # Add the sorted contours to the list\n",
    "\n",
    "    # Update the row index\n",
    "    row_idx += 1\n",
    "    bubbled = None\n",
    "    # loop over the sorted contours\n",
    "    for (j, c) in enumerate(cnts):\n",
    "        # construct a mask that reveals only the current \"bubble\" for the question\n",
    "        mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        cv2.drawContours(mask, [c], -1, 255, -1)\n",
    "        # apply the mask to the thresholded image, then count the number of non-zero pixels in the bubble area\n",
    "        mask = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "        total = cv2.countNonZero(mask)\n",
    "        # if the current total has a larger number of total non-zero pixels, then we are examining the currently bubbled-in answer\n",
    "        if bubbled is None or total > bubbled[0]:\n",
    "            bubbled = (total, j)\n",
    "\n",
    "    # initialize the contour color and the index of the \"correct\" answer\n",
    "    color = (0, 0, 255)\n",
    "    k = ANSWER_KEY[q]\n",
    "    # check to see if the bubbled answer is correct\n",
    "    if k == bubbled[1]:\n",
    "        color = (0, 255, 0)\n",
    "        correct += 1\n",
    "    # draw the outline of the correct answer on the test\n",
    "    cv2.drawContours(img_output, [cnts[k]], -1, color, 3)\n",
    "\n",
    "# grab the test taker\n",
    "score = (correct / 5.0) * 100\n",
    "print(\"[INFO] score: {:.2f}%\".format(score))\n",
    "cv2.putText(img_output, \"{:.2f}%\".format(score), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Exam\", img_output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eff4c4-dc80-49d9-877e-147743257f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
